import nltk
import re
from flask import Flask, render_template, request
from nltk.tokenize import word_tokenize,sent_tokenize
from nltk.corpus import stopwords
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from itertools import permutations
from sklearn.naive_bayes import MultinomialNB
from nltk.stem import WordNetLemmatizer
from itertools import permutations
import math
from sklearn.metrics import accuracy_score
import csv
from difflib import SequenceMatcher
from flask import Flask
lemmatizer = WordNetLemmatizer() 
stop_words = set(stopwords.words("english"))


def query(statement):
    parse_st = sent_tokenize(statement)
    parse_words = []
    key_words_stop = []
    for i in parse_st:
        j = word_tokenize(i)
        parse_words.append(j)
    for i in parse_words:
        for j in i:
            if j not in stop_words:
                key_words_stop.append(j)
    return key_words_stop







def tagger(statement):
    tokenized = sent_tokenize(statement)
    try:
        for i in tokenized:
            words = nltk.word_tokenize(i)
            tagged = nltk.pos_tag(words)
            ##print(tagged)
            array = np.array(tagged)
            key_words = []
            ##print(array)
            for row in array:
                for i in range(len(row)):
                    if (row[i] == 'JJ' or row[i]=='JJR' or row[i]=='JJS' or row[i]=='VBG' or row[i]=='VB' or row[i]=='VBN'):
                        row[1]='NN'
                
            ##print(array)
            for row in array:
                ##print(row)
                ##print(len(row))
                for i in range(len(row)):
                    ##print(row[i])
                    if (row[i] == 'WP' or row[i]=='NN' or row[i]=='WDT' or row[i]=='WRB' or row[i]=='WP$'):
                        key_words.append(row[0])

           ## print(key_words)
                    

    except Exception as e:
        print(str(e))
    return key_words


def statement_type(statement):
    df_train =  pd.read_csv('C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/simple converstion.csv') ##entering the test date base(csv)
    vectorizer = CountVectorizer()
    counts = vectorizer.fit_transform(df_train['question'].values)
    classifier = MultinomialNB()
    target = df_train['type'].values
    classifier.fit(counts,target)
    example = sent_tokenize(statement)
    example_counts = vectorizer.transform(example)
    predictions = classifier.predict(example_counts)
    return predictions


def database_cleaning():
        df =  pd.read_csv('C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/ques_ans.csv')
        words = []
        lines = np.array(df['A'])
        for i in lines:
            word = i.split()
            tagged = nltk.pos_tag(word)
            
            words.append(tagged)
        ## print(words)
        word_array = np.array(words)

        word_refesh = []
        for j in range(len(words)):
            row_list = []
            for row in words[j]:
                my_list = list(row)
                for i in range(len(my_list)):                    
                    if (my_list[i] == 'JJ' or my_list[i]=='JJR' or
                        my_list[i]=='JJS' or my_list[i]=='VBG' or
                        my_list[i]=='VB' or my_list[i]=='VBN' or my_list[i]=='PRP$'):
                        my_list[1]='NN'
                row_list.append(my_list)
            word_refesh.append(row_list)
                
        #print(word_refesh)
        key = []      
        for j in range(len(word_refesh)):
            mylist = []
            for row in word_refesh[j]:
                for i in range(len(row)):
                    if (row[i] == 'WP' or row[i]=='NN' or row[i]=='WDT' or row[i]=='WRB' or row[i]=='WP$'):
                        mylist.append(row[0])    
            key.append((mylist))
        ##print(mylist)
        #print(key)
        return key





def response_struct(prediction,key_words,key_words_stop,key,Comb_Array,statement):## prediction - statement struct; key_words - tagger ; key_words_stop, 
    if (prediction == 'Q'):
    ##print(st_parse)
        df =  pd.read_csv('C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/ques_ans.csv')
        df_combination = pd.read_csv("C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/all_combinations.csv")
        ##33print(words)
        count = []
        
        result = 0
        join_keywords = (' ').join(key_words)
        join = str(join_keywords)
        myarray = np.array(df_combination['col'])
        
        for i in myarray:
            count.append(int((SequenceMatcher(None,join,i).ratio())*10))

        print(count)

        
        if 8 in count or 9 in count or 10 in count:
            vectorizer = CountVectorizer()
            counts = vectorizer.fit_transform(df['A'].values)
            classifier = MultinomialNB()
            target = df['B'].values
            classifier.fit(counts,target)
            example = sent_tokenize(join_keywords)
            example_counts = vectorizer.transform(example)
            predictions = classifier.predict(example_counts)
            return predictions
        else:
            a = "not found"
            df2  = pd.DataFrame([[statement]], columns=list('A'))
            df_n_ans =  pd.read_csv('C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/no_ans.csv')
            df_n_ans = df_n_ans.append(df2)
            del df_n_ans['Unnamed: 0']            
            df_n_ans.to_csv('C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/no_ans.csv')
            return a

       

def comb_for_four(key):
    list_all_comb_four = []
    list4 = []
    for i in key:
        if len(i)==4:
          list4.append(i)
    #print(list4)
    for i in list4:
        for x in permutations(i):
            v = list(x)
            list_all_comb_four.append(" ".join(v))
    return list_all_comb_four

def comb_for_three(key):
    list_all_comb_three = []
    list3 = []
    for i in key:
        if len(i)==3:
          list3.append(i)
    #print(list3)
    for i in list3:
        for x in permutations(i):
            v = list(x)
            list_all_comb_three.append(" ".join(v))
    return list_all_comb_three

def comb_for_two(key):
    list_all_comb_two = []
    list2 = []
    for i in key:
        if len(i)== 2:
          list2.append(i)
    #print(list2)
    for i in list2:
        for x in permutations(i):
            v = list(x)
            list_all_comb_two.append(" ".join(v))
    return list_all_comb_two

def comb_for_five(key):
    list_all_comb_five = []
    list5 = []
    for i in key:
        if len(i)==5:
          list5.append(i)
    #print(list5)
    for i in list5:
        for x in permutations(i):
            v = list(x)
            list_all_comb_five.append(" ".join(v))
    return list_all_comb_five


def all_comb_csv(list_all_comb_four,list_all_comb_three,list_all_comb_two,list_all_comb_five):
    f = open("C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/all_combinations.csv", "w")
    f.truncate()
    columnTitleRow = [["col"]]
    writer = csv.writer(f)
    writer.writerows(columnTitleRow)
    f.close()
    
    df_comb =  pd.read_csv('C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/all_combinations.csv')

    df_comb4 = pd.DataFrame({'col':list_all_comb_four})

    df_comb3  = pd.DataFrame({'col':list_all_comb_three})
   
    df_comb2  = pd.DataFrame({'col':list_all_comb_two})
    
    df_comb5  = pd.DataFrame({'col':list_all_comb_five})
    
    df_comb   = df_comb.append(df_comb4)
    
    df_comb   = df_comb.append(df_comb3)
    
    df_comb   = df_comb.append(df_comb2)
    
    df_comb   = df_comb.append(df_comb5)

    df_comb.to_csv('C:/Users/rakshit.makan/Desktop/Python/chat bot/New WinRAR ZIP archive/Files/all_combinations.csv', sep=',')
    Comb_Array = np.array(df_comb['col'])
    print(Comb_Array.shape)
    Comb_Array = Comb_Array.reshape((len(Comb_Array),1))
    print(Comb_Array.shape)
    ##Comb_list = list(Comb_Array)
    return Comb_Array










from flask import Flask, render_template, request
app = Flask(__name__)

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/get")
def get_bot_response():
    statement = request.args.get('msg')
    key = database_cleaning()
    four = comb_for_four(key)
    three = comb_for_three(key)
    two = comb_for_two(key)
    five = comb_for_five(key)
    Comb_Array = all_comb_csv(four,three,two,five)
    key_words_stop = query(statement)
    key_words = tagger(statement)
    pred = statement_type(statement)
    result = response_struct(pred,key_words,key_words_stop,key,Comb_Array,statement)
    return str(result)

if __name__ == '__main__':
   app.run(debug = True)
